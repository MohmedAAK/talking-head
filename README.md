# talking-head

## It was adapted from 3 different model 

  1-) Tensorflowtts models-: to create speech from text link:
  
  2-) Thin-Plate Spline Motion Model: to adapt the image to video motion leading to having any motion you want on outcome video.
  
  3-) wav2lip model-: to train video on new audio to lip match the audio, hard to train because of lack of dataset availability(solved)

Although it is meant as a report, you can find parts of the code useful as Kaggle will help you a lot with training problems. (please refer to kaggle folder) 

I will enhance the usability of this code soon until then I recommend the best part as Kaggle for re-use.
